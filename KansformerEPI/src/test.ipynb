{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, time, shutil, tqdm\n",
    "import warnings, json, gzip\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# 添加包的路径\n",
    "import sys\n",
    "sys.path.insert(0, '/home/shshao/workplace/KansformerEPI/src')\n",
    "\n",
    "import epi_models\n",
    "import epi_dataset\n",
    "import misc_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "print = functools.partial(print, flush=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定显卡\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_directory(in_dir):\n",
    "    if os.path.isfile(in_dir):\n",
    "        warnings.warn(\"{} is a regular file\".format(in_dir))\n",
    "        return None\n",
    "    outdir = in_dir.rstrip('/')\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    return outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_summary(model):\n",
    "    \"\"\"\n",
    "    model: pytorch model\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    total_param = 0   \n",
    "    trainable_param = 0   \n",
    "    for i, p in enumerate(model.parameters()):\n",
    "        num_p = torch.numel(p)\n",
    "        if p.requires_grad:\n",
    "            trainable_param += num_p\n",
    "        total_param += num_p\n",
    "    return {'total_param': total_param, 'trainable_param': trainable_param}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: nn.Module, data_loader: DataLoader, device=torch.device('cuda')):   \n",
    "    model.eval()   \n",
    "    result, true_label = list(), list()  \n",
    "    for feats, _, enh_idxs, prom_idxs, labels in data_loader:   \n",
    "        feats, labels = feats.to(device), labels.to(device)  \n",
    "       \n",
    "        pred = model(feats, enh_idx=enh_idxs, prom_idx=prom_idxs) \n",
    "        pred = pred.detach().cpu().numpy()  \n",
    "        labels = labels.detach().cpu().numpy() \n",
    "        result.append(pred)  \n",
    "        true_label.append(labels)\n",
    "    result = np.concatenate(result, axis=0)\n",
    "    true_label = np.concatenate(true_label, axis=0)\n",
    "    return (result.squeeze(), true_label.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_model(\n",
    "        model_class, model_params, \n",
    "        optimizer_class, optimizer_params, \n",
    "        dataset, groups, n_folds, \n",
    "        num_epoch, patience, batch_size, num_workers,\n",
    "        outdir, checkpoint_prefix, device, use_scheduler=False) -> nn.Module:\n",
    "    bce_loss = nn.BCELoss()  \n",
    "    mse_loss = nn.MSELoss()  \n",
    "    splitter = GroupKFold(n_splits=n_folds) \n",
    " \n",
    "    wait = 0  \n",
    "    best_epoch, best_val_auc, best_val_aupr = -1, -1, -1  \n",
    "    epoch_results = {\"AUC\": list(), \"AUPR\": list()}\n",
    "   \n",
    "    for epoch_idx in range(num_epoch):\n",
    "    \n",
    "        epoch_results[\"AUC\"].append([-999 for _ in range(n_folds)])  \n",
    "        epoch_results[\"AUPR\"].append([-999 for _ in range(n_folds)])\n",
    "       \n",
    "        if epoch_idx == 0:\n",
    "            print(\"Fold splits(validation): \")\n",
    "            for fold_idx, (train_idx, valid_idx) in enumerate(splitter.split(X=groups, groups=groups)):\n",
    "                print(\"  - Fold{}: {}({})\".format(fold_idx, len(valid_idx), misc_utils.count_unique_itmes(groups[valid_idx])))\n",
    "\n",
    "        print(\"\\nCV epoch: {}/{}\\t({})\".format(epoch_idx, num_epoch, time.asctime()))\n",
    "    \n",
    "        for fold_idx, (train_idx, valid_idx) in enumerate(splitter.split(X=groups, groups=groups)):\n",
    "            train_loader = DataLoader(Subset(dataset, indices=train_idx), shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "            sample_idx = np.random.permutation(train_idx)[0:1024]\n",
    "            sample_loader = DataLoader(Subset(dataset, indices=sample_idx), shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "            valid_loader = DataLoader(Subset(dataset, indices=valid_idx), shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "            checkpoint = \"{}/{}_fold{}.pt\".format(outdir, checkpoint_prefix, fold_idx)\n",
    "          \n",
    "            if epoch_idx == 0:\n",
    "                model = model_class(**model_params).to(device)\n",
    "                optimizer = optimizer_class(model.parameters(), **optimizer_params)\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "                if os.path.exists(checkpoint):\n",
    "                    os.remove(checkpoint)\n",
    "            else:  \n",
    "                state_dict = torch.load(checkpoint)\n",
    "                model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "                optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n",
    "                scheduler.load_state_dict(state_dict[\"scheduler_state_dict\"])\n",
    "          \n",
    "            model.train()\n",
    "            for feats, dists, enh_idxs, prom_idxs, labels in tqdm.tqdm(train_loader):\n",
    "                feats, dists, labels = feats.to(device), dists.to(device), labels.to(device)\n",
    "                if hasattr(model, \"att_C\"):\n",
    "                    pred, pred_dists, att = model(feats, return_att=True, enh_idx=enh_idxs, prom_idx=prom_idxs)\n",
    "                    attT = att.transpose(1, 2)\n",
    "                    identity = torch.eye(att.size(1)).to(device)\n",
    "                    identity = Variable(identity.unsqueeze(0).expand(labels.size(0), att.size(1), att.size(1)))\n",
    "                    penal = model.l2_matrix_norm(torch.matmul(att, attT) - identity)\n",
    "\n",
    "                    loss = bce_loss(pred, labels) + (model.att_C * penal / labels.size(0)).type(torch.cuda.FloatTensor) + mse_loss(dists, pred_dists)\n",
    "                    del penal, identity\n",
    "                else:\n",
    "                    pred = model(feats, enh_idx=enh_idxs, prom_idx=prom_idxs)\n",
    "                    loss = bce_loss(pred, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if use_scheduler:\n",
    "                    scheduler.step()\n",
    "         \n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict()\n",
    "                }, checkpoint)\n",
    "\n",
    "           \n",
    "            model.eval()\n",
    "            train_pred, train_true = predict(model, sample_loader)\n",
    "            tra_AUC, tra_AUPR = misc_utils.evaluator(train_true, train_pred, out_keys=[\"AUC\", \"AUPR\"])\n",
    "            valid_pred, valid_true = predict(model, valid_loader)\n",
    "            val_AUC, val_AUPR = misc_utils.evaluator(valid_true, valid_pred, out_keys=[\"AUC\", \"AUPR\"])\n",
    "            print(\"  - Fold{}:train(AUC/AUPR)/vald(AUC/AUPR):\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t({})\".format(fold_idx, tra_AUC, tra_AUPR, val_AUC, val_AUPR, time.asctime()))\n",
    "            epoch_results[\"AUC\"][-1][fold_idx] = val_AUC\n",
    "            epoch_results[\"AUPR\"][-1][fold_idx] = val_AUPR\n",
    "\n",
    "        auc_mean, auc_std = np.mean(epoch_results[\"AUC\"][-1]), np.std(epoch_results[\"AUC\"][-1])\n",
    "        aupr_mean, aupr_std = np.mean(epoch_results[\"AUPR\"][-1]), np.std(epoch_results[\"AUPR\"][-1])\n",
    "        print(\"Epoch{:03d}(AUC/AUPR):\\t{:.4f}({:.4f})\\t{:.4f}({:.4f})\".format(epoch_idx, auc_mean, auc_std, aupr_mean, aupr_std))\n",
    "\n",
    "       \n",
    "        if auc_mean >= best_val_auc and aupr_mean >= best_val_aupr:\n",
    "            wait = 0\n",
    "            best_epoch, best_val_auc, best_val_aupr = epoch_idx, auc_mean, aupr_mean\n",
    "            print(\"Best epoch {}\\t({})\".format(best_epoch, time.asctime()))\n",
    "            for i in range(n_folds):\n",
    "                checkpoint = \"{}/{}_fold{}.pt\".format(outdir, checkpoint_prefix, i)\n",
    "                shutil.copyfile(checkpoint, \"{}.best_epoch{}.pt\".format(checkpoint.replace('.pt', ''), best_epoch))\n",
    "        else:\n",
    "            wait += 1\n",
    "            \n",
    "            if wait >= patience:\n",
    "                print(\"Early stopped ({})\".format(time.asctime()))\n",
    "                print(\"Best epoch/AUC/AUPR: {}\\t{:.4f}\\t{:.4f}\".format(best_epoch, best_val_auc, best_val_aupr))\n",
    "                break\n",
    "            else:\n",
    "                print(\"Wait{} ({})\".format(wait, time.asctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    p = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    # p.add_argument('-c', \"--config\", required=True, help=\"Configuration file for training the model\")\n",
    "    # p.add_argument('-o', \"--outdir\", required=True, help=\"Output directory\")\n",
    "    p.add_argument('-o', \"--outdir\", default='/home/shshao/workplace/KansformerEPI/output', type=str, help=\"Output directory\")\n",
    "    p.add_argument('-c', \"--config\", default='/home/shshao/workplace/KansformerEPI/dev-test/config_500bp.json', type=str, help=\"model configuration\")\n",
    "    p.add_argument('--gpu', default=1, type=int, help=\"GPU ID, (-1 for CPU)\")\n",
    "    p.add_argument('--seed', type=int, default=2020, help=\"Random seed\")\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " \n",
    "    sys.argv = sys.argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    p = get_args()   \n",
    "    args = p.parse_args()   \n",
    "    np.random.seed(args.seed)  \n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    config = json.load(open(args.config))   \n",
    "\n",
    "    print(config[\"data_opts\"])  \n",
    "    all_data = epi_dataset.EPIDataset(**config[\"data_opts\"]) \n",
    "    \n",
    "    config[\"model_opts\"][\"in_dim\"] = all_data.feat_dim\n",
    "    config[\"model_opts\"][\"seq_len\"] = config[\"data_opts\"][\"seq_len\"] // config[\"data_opts\"][\"bin_size\"]\n",
    "\n",
    "    print(\"##{}\".format(time.asctime()))\n",
    "    print(\"##command: {}\".format(' '.join(sys.argv)))\n",
    "    print(\"##config: {}\".format(config))\n",
    "    print(\"##sample size: {}\".format(len(all_data)))\n",
    "    torch.save(all_data.__getitem__(0), \"tmp.pt\")\n",
    " \n",
    "    chroms = all_data.metainfo[\"chrom\"]\n",
    "\n",
    "\n",
    "    if args.gpu >= 0:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model_class = getattr(epi_models, config[\"model_opts\"][\"model\"])\n",
    "    model = model_class(**config[\"model_opts\"])\n",
    "\n",
    "    print(model)\n",
    "    print(model_summary(model))\n",
    "    del model\n",
    "    optimizer_params = {'lr': config[\"train_opts\"][\"learning_rate\"], 'weight_decay': 1e-8}\n",
    "\n",
    "    if not os.path.isdir(args.outdir):\n",
    "        args.outdir = make_directory(args.outdir)\n",
    "\n",
    "    train_transformer_model(\n",
    "            model_class=model_class, \n",
    "            model_params=config[\"model_opts\"],\n",
    "            optimizer_class=torch.optim.AdamW, \n",
    "            optimizer_params=optimizer_params,\n",
    "            dataset=all_data,\n",
    "            groups=all_data.metainfo[\"chrom\"],\n",
    "            n_folds=5,\n",
    "            num_epoch=config[\"train_opts\"][\"num_epoch\"], \n",
    "            patience=config[\"train_opts\"][\"patience\"], \n",
    "            batch_size=config[\"train_opts\"][\"batch_size\"], \n",
    "            num_workers=config[\"train_opts\"][\"num_workers\"],\n",
    "            outdir=args.outdir, \n",
    "            checkpoint_prefix=\"checkpoint\",\n",
    "            device=device,\n",
    "            use_scheduler=config[\"train_opts\"][\"use_scheduler\"]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TransEpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
